# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14c2kWbq4OxqO3C5kfRbYIurvPrVO-koT
"""

import tensorflow as tf
mnist=tf.keras.datasets.mnist

(X_Train,Y_Train),(X_Test,Y_Test)=mnist.load_data()

print(X_Train[0])
#values are in the range 0 and 255, we shall normalize the data to restrict it between 0 and 1
X_Train=tf.keras.utils.normalize(X_train,axis=1)
print(X_Train[0])

model=tf.keras.models.Sequential()
model.add(tf.keras.layers.Flatten()) #Flattening because our data is a multi dimensional array
model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu)) #128 denotes the no of neurons in the layer.
#model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax)) #we are using softmax as we want probability distribution for output

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

model.fit(X_Train,Y_Train,epochs=3)

val_loss,val_accuracy=model.evaluate(X_Test,Y_Test)

prediction=model.predict([X_Test])
print(prediction)
import numpy 
print(numpy.argmax(prediction[1]))
plt.imshow(X_Test[2])
plt.show()